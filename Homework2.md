 
# P-Value should not be used to determine models. 

#### Abstruct: This is a brief outline of why p-value is not determinative enough when dataset is partial. One swallow does not make a summer; we should always ask this question: can your dataset represent the entire population?  P-value significancy is not the reason behind the logic of choosing such hypothesis nor model. 

### What is P-Value? 


### Real Example: NYLS97 Data

We often times see researchers using age as the independent variable to measure changes in wage. This is prevalent in labour economics and any economic field having wage as one of its' dependent variable. We control age by eliminating its effect to wage. Lets simplify the model to \(Log(Wage)=alpha + beta Age + e\).
But for students who are new to econometrics, we create our prediction model by testing and choosing the one suits the data most. Here is an example: 

To conduct the analysis, I used data from the National Longitudinal Survey of Youth 1997, consisting of responses from approximately 9000 young people aged between 12 and 16 at the time of the first interview. This is the 2011 data. Hourly pay was labled as T6658700.
```{r}
      #import NYLS97, preparation:
      mydata <- read_csv("Downloads/NYLS97/NYLS97.csv")
      colnames(mydata)<-c("year","hourpay")
      mydata["age"]<-2011-mydata["year"]
      NYLS97<-subset(mydata,hourpay>1)
      NYLS97["hourpay"]<-log(NYLS97["hourpay"])

      #run regression: linear
      NYLSfit<-lm(hourpay~age, data=NYLS97)
      coeftest(NYLSfit)
      plot(hourpay~age, data=NYLS97, main="NYLS97 Wage VS Age",xlab="Age",ylab="Wage in log")
      abline(lm(hourpay~age,data=NYLS97),col="red")

```

![NYLS97test](DoNotOpen/2011test.png)
![NYLS97plot](DoNotOpen/2011ln.png)

We can see from the graph, age has significant impact on hourly wage. This is good because it indicates that including this variable would reduce misspecification problem. However, can we say that this is the best model because of p-value os significant with 5% significant level? Can we stop here? 




### Another Example: ISLR Data

Lets look at this exmaple, this data is form the R library. I first looked at its data for entire age, then picked up data between 29-34, the same age sample NYLS97 has.

```{r}
WageTest <- subset(Wage, Wage["age"]<32 & Wage["age"]>26)
Testfit<- lm(logwage ~ age, data=WageTest)
coeftest(Testfit)
plot(logwage~ age, data=WageTest)
abline(lm(logwage~age,data=WageTest),col="green")
```

![testln](DoNotOpen/testln.png)

![ISLRTtest](DoNotOpen/ISLRTtest.png)


This looks almost exact the same to the plot generated by using NYLS97 dataset. Whoow! replication! If you think this replication can prove that your model was super good, then you are probabily deceived by P-Value. P-value only tells you that: XXXXXXXXXX


Then, lets look at the same dataset but contains age from 18 to 80. 


Lets look at another dataset which has wage data for people from 20 to 70. 
```{r}
require(AER)
require(ISLR)
fit = lm(logwage ~ poly(age,4,raw=T),data=Wage)
coeftest(fit)
plot(logwage ~ age, data=Wage, main="ISLR data Wage VS Age", xlab="Age", ylab="Wage in log")
abline(fit,col="blue")
ggplot(Wage, aes(x=age, y=logwage)) + geom_point()+stat_smooth(se=F, method='lm', formula=y~poly(x,4))
```

![Totalp4](DoNotOpen/Totalp4.png)
![ISLRTP](DoNotOpen/ISLRTP4.png)
its clear that the effect of age on wage is not linear. poly^4 explains better. 



Why? 


intuitionly, wage increase farily quick before 35 years old, because of the increasing in return of the workexperience. After 35, people generally get married, the learning ability decreases and people turn to stay in the job, less ambitous and less human caputal investment form the workplacement. Thus, the salary turn to stay the same. also people get married and have children, less time for self-improvement and sel-studying. This make sense. After 60 years old, people are going to retire and the wage will decrease. wage doesnt increase forever when age incrases. therefore the polinomial to the degree of 4 is more intuitionally correct. 

Nowlets try what if we run regression with age contrains polynomial to degree of 4 for NYLS97 dataset and Sub-ISLR dataset.



```{r}
require(ggplot2)
NYLSpoly <- lm(hourpay~poly(age,4,raw =T), data=NYLS97)
coeftest(NYLSpoly)
ggplot(NYLS97, aes(x=age, y=hourpay),main="polynomial to degree 4") +geom_point()+stat_smooth(se=F, method='lm'ï¼Œformula=y~poly(x,4))

```
![N97p4test](DoNotOpen/2011P4test.png)
![NYLSP4](DoNotOpen/2011P4.png)
NYLS Dataset


```{r}
Testpoly <- lm(logwage ~ poly(age,4,raw=T),data=WageTest)
coeftest(Testpoly)
ggplot(WageTest, aes(x=age, y=logwage)) + geom_point()+stat_smooth(se=F, method='lm', formula=y~poly(x,4))

```

![ISLRP4](DoNotOpen/ISLRP4.png)
![testp4](DoNotOpen/testp4.png)
Sub-ISLR Dataset


P-Value shows not significant, it means: including X or not is not making any difference...

But if we only have dataset for people age between 27 and 32? what should we do? We should include X^4, because intuitively......

Theory and intuitions behind the model are evidence what we depend on when determinate the model, not the P-Value. Therefore, never say: I include this variable because it has significnat P-Vlaue!!. instead, you should say: I include/did not include this variable, because intuitively poeple in this age does..... or people donot.....

